{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouvrir_json(chemin):\n",
    "    f = open(chemin, encoding=\"utf−8\") \n",
    "    toto = json.load(f)\n",
    "    f.close()\n",
    "    return toto\n",
    "def ecrire_json(dataset,chemin):\n",
    "    donnee = json.dumps(dataset, indent =2,ensure_ascii=False) \n",
    "    w = open(chemin, \"w\",encoding = \"utf-8\")\n",
    "    w.write(donnee)\n",
    "    w.close()\n",
    "    print(\"Jeu de données stocké dans %s\"%chemin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "\ts_without_punct = s\n",
    "\tfor char in string.punctuation:\n",
    "\t\ts_without_punct = s_without_punct.replace(char, ' ') # on replace les ponctuations par des espaces\n",
    "\ttokens = s_without_punct.split()\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(corpus_path):\n",
    "\t# assume there's one sentence per line, tokens separated by whitespace\n",
    "\t# simple_preprocess: \"Convert a document into a list of lowercase tokens, \n",
    "\t# ignoring tokens that are too short or too long.\"\"\n",
    "\twith open(corpus_path, mode='r', encoding='utf-8') as inFile:\n",
    "\t\treturn [preprocess(line) for line in inFile.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les étapes du prétaitement du corpus \n",
    "\n",
    "# listes des tokens à gérer ou à supprimer\n",
    "listeCaracteres={\",\":\" \", \"(\":\" \", \")\":\" \",\"\\n\":\" \", \"€\":\" \",\"=\":\" \", \"+\":\" \",\n",
    "                 \"{\":\" \", \"}\":\" \", \"\\\\\":\" \", \"\\\"\":\" \", \"«\": \" \", \"»\":\" \", \"%\":\" \", \";\":\" \",\n",
    "                 \"/\":\" \", \"_\":\" \", \": \":\" \", \" : \":\" \",\n",
    "                 \"''\":\" \"}\n",
    "listeApostropheGerable={\"d'\":\"d' \", \"t'\":\"t' \", \"j'\":\"j' \", \"m'\":\"m' \", \"s'\":\"s' \",\n",
    "                        \"l'\":\"l' \", \"n'\":\"n' \", \"qu'\": \"qu' \", \"D'\":\"D' \", \"T'\":\"T' \",\n",
    "                        \"J'\":\"J' \",\"M'\":\"M' \", \"S'\":\"S' \", \"L'\":\"L' \", \"N'\":\"N' \", \"Qu'\": \"Qu' \"}\n",
    "listePronomsInverses={\"-je\":\" je\", \"-tu\":\" tu\", \"-il\":\" il\", \"-elle\":\" elle\", \"-on\":\" on\", \"-nous\":\" nous\",\"-vous\":\" vous\",\n",
    "                      \"-ils\":\" ils\", \"-elles\":\" elles\", \"-moi\":\" moi\", \"-ce\":\" ce\"}\n",
    "listePointsFinaux=[\".\", \" .\", \" . \", \"!\", \" !\", \" ! \",\n",
    "                   \"?\", \" ?\", \" ? \"]\n",
    "listeFourreTout={\"-t\":\" t \", \"-là\":\" là \", \"@\":\" \", \"$\":\"\"}\n",
    "listeCar={\"-\":\"\", \":\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTextFromList(texte, liste):\n",
    "    for punc, substitute in liste.items():\n",
    "        texte=texte.replace(punc, substitute)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacementListe(listeCar, listeMots):\n",
    "    newMots=[]\n",
    "    for mot in listeMots:\n",
    "        if mot[0] in listeCar.keys():\n",
    "            substitute = listeCar[mot[0]]\n",
    "            new=mot.replace(mot[0], substitute)\n",
    "            newMots.append(new)\n",
    "        if mot==mot.upper():\n",
    "            mot = mot.lower()\n",
    "            newMots.append(mot)\n",
    "        else:\n",
    "            newMots.append(mot)\n",
    "    return(newMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#une fonction qui vise à gérer les mots capitalisés au début de la phrase\n",
    "def gestionMajusculeDebutPhrase(liste):\n",
    "    if len(liste)>0:\n",
    "        PremierMot=liste[0]\n",
    "        PremierMot=PremierMot.lower()\n",
    "        liste[0]=PremierMot\n",
    "        for point in listePointsFinaux:\n",
    "            for i in range(len(liste)):\n",
    "                if liste[i-1]==point:\n",
    "                    motAModifier=liste[i]\n",
    "                    motAModifier=motAModifier.lower()\n",
    "                    liste[i]=motAModifier\n",
    "    else:\n",
    "        liste = liste\n",
    "    return liste\n",
    "\n",
    "def suppressionCaracteres(liste, listeCaractere):\n",
    "    for caractere in listeCaractere:\n",
    "        for mot in liste :\n",
    "            if mot==caractere:\n",
    "                liste.remove(mot)\n",
    "            if mot==\"\":\n",
    "                liste.remove(mot) \n",
    "    return liste\n",
    "listeCar={\"-\":\"\", \":\":\"\"}\n",
    "\n",
    "def remplacementListe(listeCar, listeMots):\n",
    "    newMots=[]\n",
    "    for mot in listeMots:\n",
    "        if mot[0] in listeCar.keys():\n",
    "            substitute = listeCar[mot[0]]\n",
    "            new=mot.replace(mot[0], substitute)\n",
    "            newMots.append(new)\n",
    "        if mot==mot.upper():\n",
    "            mot = mot.lower()\n",
    "            newMots.append(mot)\n",
    "        else:\n",
    "            newMots.append(mot)\n",
    "    return(newMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def enlever_nombres(texte):\n",
    "    texte = re.sub(\"[0-9\\.]*\", \"\", texte)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupArticle_non_cap(texte):\n",
    "    metaMots = [ ]\n",
    "    texte=cleanTextFromList(texte, listeCaracteres)\n",
    "    texte=cleanTextFromList(texte, listeApostropheGerable)\n",
    "    texte=cleanTextFromList(texte, listePronomsInverses)\n",
    "    texte=cleanTextFromList(texte, listeFourreTout)\n",
    "    texte=enlever_nombres(texte)\n",
    "    mots=texte.split()\n",
    "    mots=gestionMajusculeDebutPhrase(mots)\n",
    "    mots=suppressionCaracteres(mots, listePointsFinaux)\n",
    "    mots=remplacementListe(listeCar, mots)\n",
    "    for mot in mots:\n",
    "        if mot.lower( ) not in stopwords .words(\"french\"):\n",
    "            metaMots.append(mot)\n",
    "    return metaMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiseur qui ne transforme pas les mots en majuscul\n",
    "def recupLemmatiseurGLAFF_1(cheminGLAFF):\n",
    "    lemmatiseur={}\n",
    "    with open(cheminGLAFF , \"r\", encoding=\"utf−8\") as GLAFF:\n",
    "        ligne=GLAFF.readline()\n",
    "        while ligne:\n",
    "            elems=re.split(\"\\|\", ligne)\n",
    "            forme=elems[0]\n",
    "            #forme=forme.capitalize()\n",
    "            lemme=elems[2]\n",
    "            #lemme=lemme.capitalize()\n",
    "            freq=elems[6]\n",
    "            lemmatiseur[forme]={\"lemme\":lemme , \"freq\":freq}\n",
    "            ligne=GLAFF.readline()\n",
    "    GLAFF.close()\n",
    "    return lemmatiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechercheCorrespondances(mots, lemmatiseur):\n",
    "    listeLemmes=[]\n",
    "    for mot in mots:\n",
    "        lemme=lemmatiseur.get(mot)\n",
    "        if (lemme):\n",
    "            listeLemmes.append(lemme[\"lemme\"])\n",
    "        else:\n",
    "            listeLemmes.append(mot)\n",
    "    return listeLemmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fre(corpus):\n",
    "    dic_fre = { }\n",
    "    for p in corpus:\n",
    "        mots = recupArticle_non_cap(p)\n",
    "        mots = rechercheCorrespondances(mots, lemmatiseurGLAFF)\n",
    "        for m in mots:\n",
    "            if m not in dic_fre:\n",
    "                dic_fre[m] = 1\n",
    "            else:\n",
    "                dic_fre[m] +=1\n",
    "    return dic_fre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiseurGLAFF=recupLemmatiseurGLAFF_1(\"GLAFF-1.2.2/glaff-1.2.2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données stocké dans corpus/lem/lemGlaff.json\n"
     ]
    }
   ],
   "source": [
    "#ecrire_json(lemmatiseurGLAFF,\"corpus/lem/lemGlaff.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiseurGLAFF = ouvrir_json(\"corpus/lem/lemGlaff.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_n = [ ]\n",
    "for chemin in  glob.glob('corpus/appariements_faq\\*.*')  :\n",
    "    #print(chemin)\n",
    "    corpus_q_r = ouvrir_json(chemin)\n",
    "    for k,v in corpus_q_r.items():\n",
    "        for l in v :\n",
    "            if l != \" \":\n",
    "                corpus_n.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_s = [ ]\n",
    "for chemin in  glob.glob('corpus/corpus_TALN_2007-2013\\*')[0:5]  : \n",
    "    f = open(chemin,\"r\",encoding=\"utf-8\")\n",
    "    corpus = f.read()\n",
    "    corpus_s.append(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_fre_fac = get_fre(corpus_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_fre_sci = get_fre(corpus_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_fac_plus_fre = {k:v for k,v in sorted(dic_fre_fac.items (), key=lambda i:i[1], reverse=True )}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_sci_plus_fre = {k:v for k,v in sorted(dic_fre_sci.items (), key=lambda i:i[1], reverse=True )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données stocké dans output/fre_fac.json\n",
      "Jeu de données stocké dans output/fre_sci_5arti.json\n"
     ]
    }
   ],
   "source": [
    "ecrire_json(mots_fac_plus_fre,\"output/fre_fac.json\")\n",
    "ecrire_json(mots_sci_plus_fre,\"output/fre_sci_5arti.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_fre_fac_300 = list(mots_fac_plus_fre.keys ())[0:301]\n",
    "plus_fre_sci_300 = list(mots_sci_plus_fre.keys ())[0:301]\n",
    "terme_candidat = intersection(plus_fre_fac_300, plus_fre_sci_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'trois', 'lors', 'proposer', 'tel', 'selon', 'ici', 'traiter', 'commander', 'tout', 'car', 'suivre', 'déjà', 'choisir', 'ainsi', 'très', 'utiliser', 'donc', \"d'\", 'non', 'se', 'encore', 'partir', 'commer', 'compter', 'aucun', 'alors', 'où', 'fois', 'lorsque', 'devoir', 'plusieurs', 'mettre', 'si', 'courir', 'nom', 'effectuer', 'cas', 'ne', 'chaque', 'possible', 'fin', 'réaliser', 'correspondre', 'le', 'faire', 'information', 'obtenir', 'bien', 'voir', 'prendre', 'première', 'généralement', 'afin', 'Si', 'autre', 'donner', 'deux', 'ce', 'permettre', 'après', '-', 'nombrer', 'avoir', 'rendre', 'régler', 'trouver', 'passer', 'rester', 'plaire', 'celer', 'que', 'être', 'avant', \"c'est\", 'pouvoir', 'concerner', 'également']\n"
     ]
    }
   ],
   "source": [
    "#print(terme_candidat) #??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GR(dic1,dic2):\n",
    "    dic_GR = { }\n",
    "    for m,fr in dic1.items():\n",
    "        if m in list(dic2.keys()):\n",
    "            GR =dic2[m]/fr\n",
    "            dic_GR[m] = GR\n",
    "    dic_GR_rank = {k:v for k,v in sorted(dic_GR.items (), key=lambda i:i[1], reverse=True )}\n",
    "    return dic_GR_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données stocké dans output/GR.json\n"
     ]
    }
   ],
   "source": [
    "GR = get_GR(dic_fre_fac,dic_fre_sci)\n",
    "ecrire_json(GR,\"output/GR.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_pre_dic (dic,m):\n",
    "    n = 0\n",
    "    dic_m = { }\n",
    "    for k,v in dic.items():\n",
    "        dic_m[k] =v\n",
    "        n = n+1\n",
    "        if n ==m:\n",
    "            break\n",
    "    return dic_m\n",
    "\n",
    "def get_m_der_dic (dic,m):\n",
    "    n = 0\n",
    "    dic_m = { }\n",
    "    for k,v in dic.items( ):\n",
    "        n = n+1\n",
    "        if n>len(dic)-m:\n",
    "            dic_m[k]=v\n",
    "            if n ==len(dic_m):\n",
    "                break\n",
    "    return dic_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infini_m(dic1,dic2,m):\n",
    "    dic_inf = { }\n",
    "    for mot,fr in dic1.items():\n",
    "        if mot not in list(dic2.keys()):\n",
    "            dic_inf[mot] =fr\n",
    "    dic_inf_m = get_m_pre_dic (dic_inf,m)\n",
    "    return dic_inf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données stocké dans output/GR_50_grand.json\n",
      "Jeu de données stocké dans output/GR_50_petit.json\n",
      "Jeu de données stocké dans output/Infi_50_grand.json\n"
     ]
    }
   ],
   "source": [
    "GR_50_grand =  get_m_pre_dic (GR,50)\n",
    "GR_50_petit =  get_m_der_dic (GR,50)\n",
    "Infi_50_grand = get_infini_m(dic_fre_fac,dic_fre_sci,50)\n",
    "ecrire_json(GR_50_grand,\"output/GR_50_grand.json\")\n",
    "ecrire_json(GR_50_petit,\"output/GR_50_petit.json\")\n",
    "ecrire_json(Infi_50_grand,\"output/Infi_50_grand.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(GR_50_grand)\n",
    "#print(GR_50_petit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
