{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un système d'appariement question-réponse basé sur Tf_idf (question- requête ; reponse,- document indexé par le tf*idf de chaque mot\n",
    "#dans ce document)\n",
    "#nous calculons le taux de bon appariement avec cette méthode\n",
    "# alors, maintenant, nous réfléchissons comment on peut améliorer ce système avec nos termes abtenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouvrir_json(chemin):\n",
    "    f = open(chemin, encoding=\"utf−8\") \n",
    "    toto = json.load(f)\n",
    "    f.close()\n",
    "    return toto\n",
    "def ecrire_json(dataset,chemin):\n",
    "    donnee = json.dumps(dataset, indent =2,ensure_ascii=False) \n",
    "    w = open(chemin, \"w\",encoding = \"utf-8\")\n",
    "    w.write(donnee)\n",
    "    w.close()\n",
    "    print(\"Jeu de données stocké dans %s\"%chemin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les étapes du prétaitement du corpus \n",
    "\n",
    "# listes des tokens à gérer ou à supprimer\n",
    "listeCaracteres={\",\":\" \", \"(\":\" \", \")\":\" \",\"\\n\":\" \", \"€\":\" \",\"=\":\" \", \"+\":\" \",\n",
    "                 \"{\":\" \", \"}\":\" \", \"\\\\\":\" \", \"\\\"\":\" \", \"«\": \" \", \"»\":\" \", \"%\":\" \", \";\":\" \",\n",
    "                 \"/\":\" \", \"_\":\" \", \": \":\" \", \" : \":\" \",\n",
    "                 \"''\":\" \"}\n",
    "listeApostropheGerable={\"d'\":\"d' \", \"t'\":\"t' \", \"j'\":\"j' \", \"m'\":\"m' \", \"s'\":\"s' \",\n",
    "                        \"l'\":\"l' \", \"n'\":\"n' \", \"qu'\": \"qu' \", \"D'\":\"D' \", \"T'\":\"T' \",\n",
    "                        \"J'\":\"J' \",\"M'\":\"M' \", \"S'\":\"S' \", \"L'\":\"L' \", \"N'\":\"N' \", \"Qu'\": \"Qu' \"}\n",
    "listePronomsInverses={\"-je\":\" je\", \"-tu\":\" tu\", \"-il\":\" il\", \"-elle\":\" elle\", \"-on\":\" on\", \"-nous\":\" nous\",\"-vous\":\" vous\",\n",
    "                      \"-ils\":\" ils\", \"-elles\":\" elles\", \"-moi\":\" moi\", \"-ce\":\" ce\"}\n",
    "listePointsFinaux=[\".\", \" .\", \" . \", \"!\", \" !\", \" ! \",\n",
    "                   \"?\", \" ?\", \" ? \"]\n",
    "listeFourreTout={\"-t\":\" t \", \"-là\":\" là \", \"@\":\" \", \"$\":\"\"}\n",
    "listeCar={\"-\":\"\", \":\":\"\"}\n",
    "\n",
    "def cleanTextFromList(texte, liste):\n",
    "    for punc, substitute in liste.items():\n",
    "        texte=texte.replace(punc, substitute)\n",
    "    return texte\n",
    "\n",
    "def remplacementListe(listeCar, listeMots):\n",
    "    newMots=[]\n",
    "    for mot in listeMots:\n",
    "        if mot[0] in listeCar.keys():\n",
    "            substitute = listeCar[mot[0]]\n",
    "            new=mot.replace(mot[0], substitute)\n",
    "            newMots.append(new)\n",
    "        if mot==mot.upper():\n",
    "            mot = mot.lower()\n",
    "            newMots.append(mot)\n",
    "        else:\n",
    "            newMots.append(mot)\n",
    "    return(newMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#une fonction qui vise à gérer les mots capitalisés au début de la phrase\n",
    "def gestionMajusculeDebutPhrase(liste):\n",
    "    if len(liste)>0:\n",
    "        PremierMot=liste[0]\n",
    "        PremierMot=PremierMot.lower()\n",
    "        liste[0]=PremierMot\n",
    "        for point in listePointsFinaux:\n",
    "            for i in range(len(liste)):\n",
    "                if liste[i-1]==point:\n",
    "                    motAModifier=liste[i]\n",
    "                    motAModifier=motAModifier.lower()\n",
    "                    liste[i]=motAModifier\n",
    "    else:\n",
    "        liste = liste\n",
    "    return liste\n",
    "\n",
    "def suppressionCaracteres(liste, listeCaractere):\n",
    "    for caractere in listeCaractere:\n",
    "        for mot in liste :\n",
    "            if mot==caractere:\n",
    "                liste.remove(mot)\n",
    "            if mot==\"\":\n",
    "                liste.remove(mot) \n",
    "    return liste\n",
    "listeCar={\"-\":\"\", \":\":\"\"}\n",
    "\n",
    "def remplacementListe(listeCar, listeMots):\n",
    "    newMots=[]\n",
    "    for mot in listeMots:\n",
    "        if mot[0] in listeCar.keys():\n",
    "            substitute = listeCar[mot[0]]\n",
    "            new=mot.replace(mot[0], substitute)\n",
    "            newMots.append(new)\n",
    "        if mot==mot.upper():\n",
    "            mot = mot.lower()\n",
    "            newMots.append(mot)\n",
    "        else:\n",
    "            newMots.append(mot)\n",
    "    return(newMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def enlever_nombres(texte):\n",
    "    texte = re.sub(\"[0-9\\.]*\", \"\", texte)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupArticle_non_cap(texte):\n",
    "    metaMots = [ ]\n",
    "    texte=cleanTextFromList(texte, listeCaracteres)\n",
    "    texte=cleanTextFromList(texte, listeApostropheGerable)\n",
    "    texte=cleanTextFromList(texte, listePronomsInverses)\n",
    "    texte=cleanTextFromList(texte, listeFourreTout)\n",
    "    texte=enlever_nombres(texte)\n",
    "    mots=texte.split()\n",
    "    mots=gestionMajusculeDebutPhrase(mots)\n",
    "    mots=suppressionCaracteres(mots, listePointsFinaux)\n",
    "    mots=remplacementListe(listeCar, mots)\n",
    "    for mot in mots:\n",
    "        if mot.lower( ) not in stopwords.words(\"french\"):\n",
    "            metaMots.append(mot)\n",
    "    return metaMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiseur qui ne transforme pas les mots en majuscul\n",
    "def recupLemmatiseurGLAFF_1(cheminGLAFF):\n",
    "    lemmatiseur={}\n",
    "    with open(cheminGLAFF , \"r\", encoding=\"utf−8\") as GLAFF:\n",
    "        ligne=GLAFF.readline()\n",
    "        while ligne:\n",
    "            elems=re.split(\"\\|\", ligne)\n",
    "            forme=elems[0]\n",
    "            #forme=forme.capitalize()\n",
    "            lemme=elems[2]\n",
    "            #lemme=lemme.capitalize()\n",
    "            freq=elems[6]\n",
    "            lemmatiseur[forme]={\"lemme\":lemme , \"freq\":float(freq)}\n",
    "            ligne=GLAFF.readline()\n",
    "    GLAFF.close()\n",
    "    return lemmatiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechercheCorrespondances(mots, lemmatiseur):\n",
    "    listeLemmes=[]\n",
    "    for mot in mots:\n",
    "        lemme=lemmatiseur.get(mot)\n",
    "        if (lemme):\n",
    "            listeLemmes.append(lemme[\"lemme\"])\n",
    "        else:\n",
    "            listeLemmes.append(mot)\n",
    "    return listeLemmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mot_nor(liste):\n",
    "    mots =  recupArticle_non_cap(liste)\n",
    "    mots =  rechercheCorrespondances(mots,lemmatiseurGLAFF)\n",
    "    return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiseurGLAFF = ouvrir_json(\"corpus/lem/lemGlaff.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_R ={ }\n",
    "for chemin in  glob.glob('corpus/QA\\*.*')  :\n",
    "    #print(chemin)\n",
    "    corpus_q_r = ouvrir_json(chemin)\n",
    "    for k,v in corpus_q_r.items():\n",
    "        Q = v[0]\n",
    "        A=v[1]\n",
    "        Q_R[Q] = A\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_liste = list(Q_R.keys( ))\n",
    "R_liste = list(Q_R.values( ))\n",
    "#print(len(Q_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma_q_a(liste):\n",
    "    n = 0 \n",
    "    dic_nor = { }\n",
    "    while n<len(liste):\n",
    "        dic_nor[n] = get_mot_nor(liste[n])\n",
    "        n=n+1\n",
    "    return dic_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulaire(articles): #obtenir un vocabulaire propre de nos documents de base (des réponses)\n",
    "    vocabulaire = [ ]\n",
    "    for keys, values in articles.items():\n",
    "        for mot in values:\n",
    "            if mot not in vocabulaire:\n",
    "                vocabulaire.append(mot)\n",
    "    return(vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(articles):  #obtenir un index qui qui associe un mot vers une liste de documents contenant ce mot \n",
    "    vocabulaire = get_vocabulaire(articles)\n",
    "    myindex = { }\n",
    "    for m in set(vocabulaire):\n",
    "        if not m in myindex:\n",
    "            myindex[m]=[]\n",
    "        for d in articles:\n",
    "            if m in articles[d]:\n",
    "                myindex[m].append(d)\n",
    "    return myindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_Idf(Index_mots,articles):  #on obtient le IDF de chaque mot\n",
    "    dic_Idf={}\n",
    "    for keys, values in Index_mots.items():\n",
    "        dic_Idf[keys] = math.log10(len(articles)/len(values))\n",
    "    return dic_Idf\n",
    "def get_Tf(articles):  #on obtien le TF de chaque mot dans chaque document\n",
    "    dic_Tf = { }\n",
    "    for k,v in articles.items():\n",
    "        wordcount={}\n",
    "        for mot in v:\n",
    "            if mot not in wordcount:\n",
    "                wordcount[mot] = v.count(mot) /len(v)\n",
    "        dic_Tf[k]= wordcount\n",
    "    return(dic_Tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(dic_tf,dic_idf): #on obtient le score de TF*IDF pour chaque mot de chaque q\n",
    "    dic_tf_idf = {}\n",
    "    for k, v in dic_tf.items( ):\n",
    "        for m,tf in v.items():\n",
    "            tf_idf = tf * dic_idf[m]\n",
    "            v[m]=tf_idf\n",
    "        dic_tf_idf[k] = v\n",
    "    return dic_tf_idf #  {id_1 : [mot1 : tf*idf, mot2 : tif*idf....]...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecteur_req(req): # on utilise des chiffres(le TF*IDF de chaque mot) pour représenter la requête\n",
    "    req = get_mot_nor(req)\n",
    "    req_vecteur = [ ]\n",
    "    req_tf = { }\n",
    "    for mot in req:\n",
    "        if mot not in req_tf :\n",
    "            req_tf[mot] =  req.count(mot) /len(req)\n",
    "    #print(req_tf)\n",
    "    for mot in req:\n",
    "        #print(mot)\n",
    "        if mot in vec :\n",
    "            mot_tf_idf = req_tf[mot]*Idf_R[mot]\n",
    "            req_vecteur.append(mot_tf_idf)\n",
    "        else:\n",
    "            req_vecteur.append(0)\n",
    "    return req_vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecteur_doc(req,liste_id,articles):# on utilise des chiffres(le TF*IDF de chaque mot de requête dans chaque q) pour représenter chaque article\n",
    "    doc_vecteur = { }# liste_id : la liste des q qui contiennent un (ou plusieurs) mot de la requête  \n",
    "    req = get_mot_nor(req)\n",
    "    for id_q in liste_id:\n",
    "        vecteur = [ ]\n",
    "        #mots = mots_tf_idf[id_art]\n",
    "        for m in req:\n",
    "            #vecteur = [ ]\n",
    "            if m in articles[id_q]:\n",
    "                m_tf_idf = Tf_Idf_R[id_q][m]\n",
    "            else:\n",
    "                m_tf_idf = 0\n",
    "            vecteur.append(m_tf_idf)\n",
    "        if len(vecteur) != vecteur.count(0):\n",
    "            doc_vecteur[id_q] = vecteur\n",
    "    return doc_vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_pre_dic (dic,m):\n",
    "    n = 0\n",
    "    dic_m = { }\n",
    "    for k,v in dic.items():\n",
    "        dic_m[k] =v\n",
    "        n = n+1\n",
    "        if n ==m:\n",
    "            break\n",
    "    return dic_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_corre_q(vecteur_req,vecteur_doc): \n",
    "    ranking =  { }\n",
    "    for k,v in vecteur_doc.items():\n",
    "        cos_sim = dot(vecteur_req,v)/(norm(vecteur_req)*norm(v)) #modèl pour calculer le taux de similarité\n",
    "        ranking[k]=cos_sim   # dictionnaire {id : taux de similarité}\n",
    "    sorted_ranking={k:v for k,v in sorted(ranking.items (), key=lambda i:i[1], reverse=True )}#mettre le ranking en ordre\n",
    "    q_corres = get_m_pre_dic(sorted_ranking,1) #q correspondant et probabilité\n",
    "    return q_corres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recher_reponse(q_corres,R_liste):\n",
    "    dic = { }\n",
    "    for q,pro in q_corres.items( ):\n",
    "        reponse = R_liste[q]\n",
    "    dic[reponse] = pro\n",
    "    print(\"Reponse : \", reponse)\n",
    "    print(\"Probabilité : \", pro)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_nor = norma_q_a(R_liste)\n",
    "#print(len(R_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = get_vocabulaire(R_nor)\n",
    "index = get_index(R_nor)\n",
    "Idf_R = get_Idf(index,R_nor)\n",
    "Tf_R = get_Tf(R_nor)\n",
    "Tf_Idf_R = get_tf_idf(Tf_R,Idf_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31206104864419226, 0.2384656915852734, 0.2870733013225323, 0.17825969245247714, 0]\n",
      "{1: [0, 0, 0.027082386917220022, 0, 0], 2: [0, 0.027728568788985275, 0, 0, 0], 3: [0, 0.01064578980291399, 0, 0, 0], 4: [0, 0.056777545615541276, 0, 0, 0], 5: [0, 0.03506848405665785, 0, 0, 0], 6: [0, 0, 0.028144441306130613, 0, 0], 9: [0, 0, 0, 0.022282461556559642, 0], 10: [0, 0, 0, 0.02583473803659089, 0], 12: [0, 0, 0, 0.0557061538913991, 0], 14: [0, 0.03222509345746938, 0.11638106810372931, 0.07226744288613939, 0], 15: [0, 0, 0, 0.018189764535967053, 0], 17: [0.05572518725789147, 0, 0, 0.031832087937942344, 0], 19: [0, 0, 0, 0.019806632494719683, 0], 20: [0, 0, 0, 0.05242932130955209, 0], 21: [0, 0, 0, 0.024089147628713125, 0], 22: [0.022613119466970453, 0, 0, 0.012917369018295445, 0], 23: [0, 0, 0, 0.02970994874207952, 0], 29: [0, 0, 0, 0.07750421410977267, 0], 31: [0, 0, 0, 0.037137435927599396, 0], 54: [0, 0, 0, 0.037137435927599396, 0], 89: [0, 0, 0.05126308952188076, 0, 0], 97: [0, 0.056777545615541276, 0, 0, 0], 99: [0.011306559733485226, 0, 0, 0, 0], 107: [0, 0.01124838167855063, 0, 0, 0]}\n",
      "{14: 0.7402758133536737}\n",
      "Reponse :  L’inscription administrative sur RDV (en présentiel) ne s’adresse qu’aux primo-entrants à Paris-Sorbonne (quel que soit leur niveau d’inscription)\\.\n",
      "Vous pourrez prendre rendez-vous à partir de début juillet pour la première session des inscriptions administratives en présentiel, et à compter du 24 août 2017 pour la seconde session de la campagne\\.\n",
      "Prendre rendez-vous pour une 1ère inscription en licence\\.\n",
      "Prendre rendez-vous pour une 1ère inscription en master\\.\n",
      " \n",
      "Probabilité :  0.7402758133536737\n"
     ]
    }
   ],
   "source": [
    "#Test \n",
    "req = \" Comment prendre rendez-vous pour mon inscription administrative ? \"\n",
    "liste_id = list(R_nor.keys( ))\n",
    "vec_req =  get_vecteur_req(req)\n",
    "print(vec_req)\n",
    "vec_doc = get_vecteur_doc(req,liste_id,R_nor)\n",
    "print(vec_doc)\n",
    "resul = recherche_corre_q(vec_req,vec_doc)\n",
    "print(resul)\n",
    "reponse = recher_reponse(resul,R_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apparie_q_r(q_dic):\n",
    "    dic_apparie = { }\n",
    "    for id_, q in q_dic.items( ):\n",
    "        vec_q = get_vecteur_req(q)\n",
    "        vec_doc = get_vecteur_doc(q,liste_id,R_nor)\n",
    "        id_corre = list(recherche_corre_q(vec_q,vec_doc).keys( ))[0]\n",
    "        dic_apparie[id_] = id_corre\n",
    "    return dic_apparie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dic = { }\n",
    "n=0\n",
    "while n < len(Q_liste):\n",
    "    q_dic[n]=Q_liste[n]\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 99, 1: 1, 2: 6, 3: 99, 4: 2, 5: 6, 6: 6, 7: 10, 8: 9, 9: 8, 10: 22, 11: 38, 12: 12, 13: 13, 14: 14, 15: 9, 16: 16, 17: 10, 18: 18, 19: 21, 20: 21, 21: 21, 22: 22, 23: 23, 24: 99, 25: 31, 26: 45, 27: 90, 28: 28, 29: 30, 30: 30, 31: 22, 32: 30, 33: 3, 34: 30, 35: 12, 36: 37, 37: 37, 38: 44, 39: 10, 40: 107, 41: 8, 42: 42, 43: 42, 44: 75, 45: 9, 46: 21, 47: 96, 48: 50, 49: 107, 50: 107, 51: 78, 52: 99, 53: 56, 54: 99, 55: 99, 56: 22, 57: 99, 58: 107, 59: 64, 60: 10, 61: 75, 62: 99, 63: 49, 64: 64, 65: 1, 66: 107, 67: 52, 68: 9, 69: 10, 70: 102, 71: 107, 72: 3, 73: 39, 74: 75, 75: 75, 76: 15, 77: 77, 78: 107, 79: 107, 80: 70, 81: 107, 82: 75, 83: 58, 84: 52, 85: 107, 86: 107, 87: 19, 88: 64, 89: 64, 90: 49, 91: 75, 92: 92, 93: 107, 94: 96, 95: 107, 96: 78, 97: 17, 98: 99, 99: 1, 100: 27, 101: 9, 102: 75, 103: 42, 104: 9, 105: 99, 106: 107, 107: 99, 108: 108}\n"
     ]
    }
   ],
   "source": [
    "resultat = apparie_q_r(q_dic)\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taux_de_correction : 0.1743119266055046\n"
     ]
    }
   ],
   "source": [
    "nb_corre = 0\n",
    "for k,v in resultat.items( ):\n",
    "    if k == v:\n",
    "        nb_corre = nb_corre+1\n",
    "        \n",
    "taux_corre = nb_corre/len(list((resultat.keys())))\n",
    "print(\"taux_de_correction :\", taux_corre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
